{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNo9VfuSBpo9nxNSyIKDSJA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lostaim/MachineLearning/blob/main/lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eK3dyWmk66_8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as mtp\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_coef(x,y):\n",
        "  n = np.size(x);\n",
        "  m_x = np.mean(x);\n",
        "  m_y = np.mean(y);\n",
        "  ss_xy = np.sum(y*x) - n*m_y*m_x\n",
        "  ss_xx = np.sum(x*x) - n*m_x*m_x\n",
        "\n",
        "  b_1 = ss_xy / ss_xx\n",
        "  b_0 = m_y - b_1*m_x\n",
        "\n",
        "  return(b_0, b_1)\n",
        "\n",
        "def plot_reg(x,y,b):\n",
        "  mtp.scatter(x,y,color='m', marker = 'o', s=30)\n",
        "  y_pred = b[0] + b[1]*x\n",
        "  mtp.plot(x, y_pred, color = 'g')\n",
        "  mtp.xlabel('x')\n",
        "  mtp.ylabel('y')\n",
        "\n",
        "  mtp.show()\n",
        "\n",
        "def main():\n",
        "  x = np.array([0,10,2,30,4,50,6,70,80])\n",
        "  y = np.array([0,1,20,3,40,5,60,7,8])\n",
        "\n",
        "  b = estimate_coef(x,y);\n",
        "  print(\"estimated coefficients:\\nb_0 = {}\\nb_1 = {}\".format(b[0],b[1]))\n",
        "\n",
        "  plot_reg(x,y,b)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n"
      ],
      "metadata": {
        "id": "yBUfB09vQFoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ridge regression-\n",
        "the cost function in ridge regression adds up an additional parameter called as  λ * (slope)2,penalty.therefore the cost function returns cost function.\n",
        "->when there is a unit change in x  variable which result in a higher unit change in y var. \n",
        "->we penalise the feature to get the best fit line.\n",
        "the lambda value can range from 0 to any positive value.\n",
        "when we have multiple features the cost function for ridge reggresion becomes \n",
        "(ading multiple penalties).\n",
        "\n",
        "lasso regression-\n",
        "->add λ * |slope| to cost function\n",
        "in lasso regression the line moves in any lower value slope whereas in ridge regeression the line moves towards zero .\n",
        "in lasso regeression the variables with lower scope values are removed/eliminated, ridge regression will never reach zero or eliminiate variables.\n"
      ],
      "metadata": {
        "id": "W50xIfmlRVOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as mpt\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import load_boston\n",
        "\n",
        "\n",
        "df = load_boston()\n",
        "dataset= pd.DataFrame(df.data)\n",
        "df.target.shape\n",
        "dataset[\"Price\"]=df.target\n",
        "X = dataset.iloc[:,:-1]\n",
        "y = dataset.iloc[:,:-1]\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "lin_regressor=LinearRegression()\n",
        "mse=cross_val_score(lin_regressor,X,y,scoring='neg_mean_squared_error',cv=5)\n",
        "mean_mse=np.mean(mse)\n",
        "print(mean_mse)\n",
        "\n",
        "\n",
        "ridge=Ridge()\n",
        "parameters={'alpha':[1,5,10,20,30,35,40,45,50,55,100]}\n",
        "\n",
        "ridge_regressor=GridSearchCV(ridge,parameters,scoring='neg_mean_squared_error',cv=5)\n",
        "ridge_regressor.fit(X,y)\n",
        "print(\"\\n\")\n",
        "print(\"ridge regression\")\n",
        "print(ridge_regressor.best_params_)\n",
        "print(ridge_regressor.best_score_)\n",
        "\n",
        "\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "lasso=Lasso()\n",
        "parameters={'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20,30,35,40,45,50,55,100]}\n",
        "lasso_regressor=GridSearchCV(lasso,parameters,scoring='neg_mean_squared_error',cv=5)\n",
        "\n",
        "lasso_regressor.fit(X,y)\n",
        "print(\"\\n\")\n",
        "print(\"lasso regression\")\n",
        "print(lasso_regressor.best_params_)\n",
        "print(lasso_regressor.best_score_)\n",
        "\n",
        "'''\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "'''"
      ],
      "metadata": {
        "id": "IcRLFtZ_gQzF",
        "outputId": "1297c920-3cae-4db4-eb6c-d85b07c08669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 871
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
            "\n",
            "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
            "    the documentation of this function for further details.\n",
            "\n",
            "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
            "    dataset unless the purpose of the code is to study and educate about\n",
            "    ethical issues in data science and machine learning.\n",
            "\n",
            "    In this special case, you can fetch the dataset from the original\n",
            "    source::\n",
            "\n",
            "        import pandas as pd\n",
            "        import numpy as np\n",
            "\n",
            "\n",
            "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
            "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
            "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
            "        target = raw_df.values[1::2, 2]\n",
            "\n",
            "    Alternative datasets include the California housing dataset (i.e.\n",
            "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
            "    dataset. You can load the datasets as follows::\n",
            "\n",
            "        from sklearn.datasets import fetch_california_housing\n",
            "        housing = fetch_california_housing()\n",
            "\n",
            "    for the California housing dataset and::\n",
            "\n",
            "        from sklearn.datasets import fetch_openml\n",
            "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
            "\n",
            "    for the Ames housing dataset.\n",
            "    \n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-9.675731633390693e-26\n",
            "\n",
            "\n",
            "ridge regression\n",
            "{'alpha': 1}\n",
            "-0.00015586935799189833\n",
            "\n",
            "\n",
            "lasso regression\n",
            "{'alpha': 1e-08}\n",
            "-1.3381973654965102e-07\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom sklearn.model_selection import train_test_split\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}