{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRIiHjBO6zZmA8lfjPAMPX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepakjongra/MachineLearning/blob/main/data_preprocessing_and_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Complaint Classification using NLP</h1>"
      ],
      "metadata": {
        "id": "NKc8ckDbBKcU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vIO8pBve_tDp"
      },
      "outputs": [],
      "source": [
        "!pip install pandas numpy transformers torch indic-nlp-library googletrans==4.0.0-rc1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import pipeline\n",
        "from googletrans import Translator\n",
        "from indicnlp.normalize import indic_normalize"
      ],
      "metadata": {
        "id": "UPiRNspEAOXY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    \"complaint_id\": [1, 2, 3, 4],\n",
        "    \"text\": [\n",
        "        \"‡§™‡§æ‡§£‡•Ä ‡§®‡§æ‡§π‡•Ä ‡§Ü‡§π‡•á, ‡§Æ‡§¶‡§§ ‡§ï‡§∞‡§æ!\",  # Marathi\n",
        "        \"‡§¨‡§ø‡§ú‡§≤‡•Ä ‡§ï‡§ü ‡§π‡•ã ‡§ó‡§à ‡§π‡•à\",       # Hindi\n",
        "        \"There is a pothole on the road\",  # English\n",
        "        \"Garbage is not collected since 3 days\"  # English\n",
        "    ],\n",
        "    \"language\": [\"mr\", \"hi\", \"en\", \"en\"]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "VoIAwbc7AioF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator()\n",
        "\n",
        "def translate_to_marathi(text, lang):\n",
        "    if lang == \"mr\":  # Already in Marathi\n",
        "        return text\n",
        "    try:\n",
        "        translated = translator.translate(text, src=lang, dest=\"mr\")\n",
        "        return translated.text\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "df[\"translated_text\"] = df.apply(lambda x: translate_to_marathi(x[\"text\"], x[\"language\"]), axis=1)\n",
        "\n",
        "df[[\"text\", \"translated_text\"]]\n"
      ],
      "metadata": {
        "id": "vZUGPZVYAnYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalizer = indic_normalize.DevanagariNormalizer()\n",
        "\n",
        "def normalize_text(text):\n",
        "    return normalizer.normalize(text)\n",
        "\n",
        "df[\"normalized_text\"] = df[\"translated_text\"].apply(normalize_text)\n",
        "df[[\"translated_text\", \"normalized_text\"]]\n"
      ],
      "metadata": {
        "id": "xcJgSutXAquf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch"
      ],
      "metadata": {
        "id": "mxvZlsvKA6yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "EMsYJffLBGLn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Define the categories from Maharashtra Govt Departments\n",
        "categories = [\n",
        "    \"Home Department\", \"Urban Development Department\", \"Public Works Department\",\n",
        "    \"Water Resources Department\", \"Energy Department\", \"Health Department\",\n",
        "    \"Education Department\", \"Food, Civil Supplies, and Consumer Protection Department\",\n",
        "    \"Environment and Climate Change Department\", \"Social Justice Department\",\n",
        "    \"Tribal Development Department\", \"Agriculture Department\", \"Labour Department\",\n",
        "    \"Transport Department\", \"Tourism Department\"\n",
        "]\n",
        "\n",
        "# Load IndicBERT Model and Tokenizer\n",
        "model_name = \"ai4bharat/indic-bert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(categories))\n"
      ],
      "metadata": {
        "id": "-XjD6f3dBekw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_complaint_indicbert(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    predicted_class = torch.argmax(outputs.logits).item()\n",
        "    return categories[predicted_class]\n",
        "\n",
        "# Sample Complaint\n",
        "complaint_text = \"‡§¨‡§ø‡§ú‡§≤‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à, ‡§¨‡§π‡•Å‡§§ ‡§¶‡§ø‡§ï‡•ç‡§ï‡§§ ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\"\n",
        "predicted_department = classify_complaint_indicbert(complaint_text)\n",
        "print(f\"Complaint: {complaint_text}\\nPredicted Department: {predicted_department}\")\n",
        "\n",
        "# Sample Complaints DataFrame\n",
        "data = {\n",
        "    \"complaint_text\": [\n",
        "        \"‡§™‡§æ‡§®‡•Ä ‡§ï‡•Ä ‡§∏‡§™‡•ç‡§≤‡§æ‡§à ‡§¨‡§Ç‡§¶ ‡§π‡•à, ‡§ï‡•Å‡§õ ‡§ï‡•Ä‡§ú‡§ø‡§è!\",\n",
        "        \"‡§∞‡§æ‡§∏‡•ç‡§§‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§π‡•Å‡§§ ‡§ó‡§°‡•ç‡§¢‡•á ‡§π‡•à‡§Ç, ‡§∏‡§´‡§∞ ‡§Æ‡•Å‡§∂‡•ç‡§ï‡§ø‡§≤ ‡§π‡•ã ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§\",\n",
        "        \"‡§∞‡§æ‡§∂‡§® ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§™‡§∞ ‡§≤‡•Ç‡§ü‡§ñ‡§∏‡•ã‡§ü ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Apply Classification to Each Complaint\n",
        "df[\"department\"] = df[\"complaint_text\"].apply(classify_complaint_indicbert)\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfuvM5VdDFq6",
        "outputId": "188fda29-c74a-4bc1-c883-7cdee63e858d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complaint: ‡§¨‡§ø‡§ú‡§≤‡•Ä ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à, ‡§¨‡§π‡•Å‡§§ ‡§¶‡§ø‡§ï‡•ç‡§ï‡§§ ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à‡•§\n",
            "Predicted Department: Environment and Climate Change Department\n",
            "                                      complaint_text  \\\n",
            "0                  ‡§™‡§æ‡§®‡•Ä ‡§ï‡•Ä ‡§∏‡§™‡•ç‡§≤‡§æ‡§à ‡§¨‡§Ç‡§¶ ‡§π‡•à, ‡§ï‡•Å‡§õ ‡§ï‡•Ä‡§ú‡§ø‡§è!   \n",
            "1  ‡§∞‡§æ‡§∏‡•ç‡§§‡•á ‡§Æ‡•á‡§Ç ‡§¨‡§π‡•Å‡§§ ‡§ó‡§°‡•ç‡§¢‡•á ‡§π‡•à‡§Ç, ‡§∏‡§´‡§∞ ‡§Æ‡•Å‡§∂‡•ç‡§ï‡§ø‡§≤ ‡§π‡•ã ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§   \n",
            "2                ‡§∞‡§æ‡§∂‡§® ‡§ï‡•Ä ‡§¶‡•Å‡§ï‡§æ‡§® ‡§™‡§∞ ‡§≤‡•Ç‡§ü‡§ñ‡§∏‡•ã‡§ü ‡§π‡•ã ‡§∞‡§π‡•Ä ‡§π‡•à‡•§   \n",
            "\n",
            "                                  department  \n",
            "0  Environment and Climate Change Department  \n",
            "1  Environment and Climate Change Department  \n",
            "2  Environment and Climate Change Department  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Fine Tunning Model</h1>"
      ],
      "metadata": {
        "id": "JLaHN2o2Dkm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch datasets sentencepiece scikit-learn"
      ],
      "metadata": {
        "id": "rMVsNORkDkW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Load Pretrained IndicBERT</h1>"
      ],
      "metadata": {
        "id": "O87Y6BLoDtw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define categories (Departments of Maharashtra Government) - Remove duplicate \"Labour Department\"\n",
        "categories = [\n",
        "    \"School Education and Sports\", \"Agriculture Department\", \"Co-operation, Marketing and Textiles Department\",\n",
        "    \"Dairy Development Department\", \"Department Of Animal Husbandry\", \"Department Of Minority Development\",\n",
        "    \"Department of Industries, Energy, Labor and Mines\", \"Department of Sainik Welfare\",\n",
        "    \"Environment and Climate Change Department\", \"Finance Department\",\n",
        "    \"Fisheries Department\", \"Food, Civil Supplies and Consumer Protection Department\", \"Forest Department\",\n",
        "    \"General Administration Department\", \"Law and Judiciary Department\", \"Higher and Technical Education Department\",\n",
        "    \"Housing Department\", \"Labour Department\", \"Greater Mumbai Police\"\n",
        "]\n",
        "\n",
        "# Load IndicBERT Model and Tokenizer\n",
        "model_name = \"ai4bharat/indic-bert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(categories))"
      ],
      "metadata": {
        "id": "jqCOg0P1Dr-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"./complaints.csv\")\n",
        "\n",
        "# üîπ Check for NaN values in the department column\n",
        "df = df.dropna(subset=[\"department\", \"complaint_text\"])  # Remove missing values\n",
        "\n",
        "# üîπ Convert department names to numerical labels\n",
        "label_map = {dept: i for i, dept in enumerate(categories)}\n",
        "df[\"label\"] = df[\"department\"].map(label_map)\n",
        "\n",
        "# üîπ Remove rows where the department is not in label_map (i.e., NaN labels)\n",
        "df = df.dropna(subset=[\"label\"])\n",
        "df[\"label\"] = df[\"label\"].astype(int)  # Ensure labels are integers\n",
        "\n",
        "# Split into Train & Validation\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df[\"complaint_text\"].tolist(), df[\"label\"].tolist(), test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Tokenize Data\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512)\n",
        "\n",
        "# Convert to Hugging Face Dataset (Ensuring Labels are Torch LongTensors)\n",
        "train_dataset = Dataset.from_dict({\n",
        "    \"input_ids\": train_encodings[\"input_ids\"],\n",
        "    \"attention_mask\": train_encodings[\"attention_mask\"],\n",
        "    \"labels\": torch.tensor(train_labels, dtype=torch.long)  # üîπ FIX: Ensure correct label format\n",
        "})\n",
        "\n",
        "val_dataset = Dataset.from_dict({\n",
        "    \"input_ids\": val_encodings[\"input_ids\"],\n",
        "    \"attention_mask\": val_encodings[\"attention_mask\"],\n",
        "    \"labels\": torch.tensor(val_labels, dtype=torch.long)  # üîπ FIX: Ensure correct label format\n",
        "})\n",
        "\n"
      ],
      "metadata": {
        "id": "WPp5vg81D4eX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=10,  # Increase training cycles\n",
        "    per_device_train_batch_size=16,  # If GPU can handle more\n",
        "    per_device_eval_batch_size=16,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=3e-5,  # Adjust learning rate\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1E95ry6Hmp9",
        "outputId": "30beb779-015b-4d42-b63f-c6c08810fb7e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Model\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "hqtXOlESHqoN",
        "outputId": "efd76e67-7fc2-40ed-e352-fc72ab3c85b4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 1:34:09, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.659791</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.145175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.538072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.154503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.855028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.635423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.481551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.383515</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.314073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.174100</td>\n",
              "      <td>0.288564</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=1.17413623046875, metrics={'train_runtime': 5664.2043, 'train_samples_per_second': 1.412, 'train_steps_per_second': 0.088, 'total_flos': 24686332704000.0, 'train_loss': 1.17413623046875, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define save path\n",
        "save_directory = \"./fine_tuned_indic_bert\"\n",
        "\n",
        "# Save model and tokenizer\n",
        "model.save_pretrained(save_directory)\n",
        "tokenizer.save_pretrained(save_directory)\n",
        "\n",
        "print(f\"Model saved to {save_directory}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79JNj83T2bF9",
        "outputId": "a8985609-f7de-464b-dae9-7d9d8bdaeaaf"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to ./fine_tuned_indic_bert\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = trainer.evaluate()\n",
        "print(metrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "hgrW6CR3YW5v",
        "outputId": "87b72fbe-30ef-454b-90f7-a67093a76952"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 00:40]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 0.2885638475418091, 'eval_runtime': 43.537, 'eval_samples_per_second': 4.594, 'eval_steps_per_second': 0.299, 'epoch': 10.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the fine-tuned model\n",
        "model_name = \"./fine_tuned_indic_bert\"  # Path where your model is saved\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "# Ensure model is on the correct device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKMK3bYLzmsA",
        "outputId": "eb108115-78b1-4e33-ba8c-bba683b8d684"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlbertForSequenceClassification(\n",
              "  (albert): AlbertModel(\n",
              "    (embeddings): AlbertEmbeddings(\n",
              "      (word_embeddings): Embedding(200000, 128, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 128)\n",
              "      (token_type_embeddings): Embedding(2, 128)\n",
              "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0, inplace=False)\n",
              "    )\n",
              "    (encoder): AlbertTransformer(\n",
              "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
              "      (albert_layer_groups): ModuleList(\n",
              "        (0): AlbertLayerGroup(\n",
              "          (albert_layers): ModuleList(\n",
              "            (0): AlbertLayer(\n",
              "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (attention): AlbertSdpaAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (attention_dropout): Dropout(p=0, inplace=False)\n",
              "                (output_dropout): Dropout(p=0, inplace=False)\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              )\n",
              "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (activation): GELUActivation()\n",
              "              (dropout): Dropout(p=0, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (pooler_activation): Tanh()\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=19, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_texts = [\n",
        "    \"‡§Æ‡§æ‡§ù‡•ç‡§Ø‡§æ ‡§ó‡§æ‡§µ‡§æ‡§§‡•Ä‡§≤ ‡§∞‡§∏‡•ç‡§§‡•ç‡§Ø‡§æ‡§ö‡•Ä ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ ‡§ñ‡•Ç‡§™‡§ö ‡§µ‡§æ‡§à‡§ü ‡§Ü‡§π‡•á. ‡§™‡§æ‡§µ‡§∏‡§æ‡§≥‡•ç‡§Ø‡§æ‡§§ ‡§ö‡§ø‡§ñ‡§≤‡§æ‡§Æ‡•Å‡§≥‡•á ‡§≤‡•ã‡§ï‡§æ‡§Ç‡§®‡§æ ‡§ö‡§æ‡§≤‡§£‡•á‡§π‡•Ä ‡§ï‡§†‡•Ä‡§£ ‡§π‡•ã‡§§‡•á.\",\n",
        "    \"‡§∂‡•á‡§§‡§ï‡§±‡•ç‡§Ø‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§®‡§µ‡•Ä‡§® ‡§Ö‡§®‡•Å‡§¶‡§æ‡§® ‡§ï‡§ß‡•Ä ‡§Æ‡§ø‡§≥‡§£‡§æ‡§∞? ‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä ‡§Æ‡§¶‡§§‡•Ä‡§ö‡§æ ‡§≤‡§æ‡§≠ ‡§Ü‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§Æ‡§ø‡§≥‡§æ‡§µ‡§æ.\",\n",
        "    \"‡§µ‡§ø‡§ú‡•á‡§ö‡§æ ‡§∏‡§§‡§§ ‡§™‡•Å‡§∞‡§µ‡§†‡§æ ‡§ñ‡§Ç‡§°‡§ø‡§§ ‡§π‡•ã‡§§‡•ã. ‡§Ü‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§ñ‡•Ç‡§™ ‡§Ö‡§°‡§ö‡§£ ‡§π‡•ã‡§§‡•á, ‡§ï‡•É‡§™‡§Ø‡§æ ‡§ï‡§æ‡§π‡•Ä‡§§‡§∞‡•Ä ‡§â‡§™‡§æ‡§Ø ‡§ï‡§∞‡§æ.\",\n",
        "    \"‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä ‡§∞‡•Å‡§ó‡•ç‡§£‡§æ‡§≤‡§Ø‡§æ‡§§ ‡§î‡§∑‡§ß‡§æ‡§Ç‡§ö‡§æ ‡§§‡•Å‡§ü‡§µ‡§°‡§æ ‡§Ü‡§π‡•á. ‡§ó‡§∞‡§ú‡•Ç ‡§∞‡•Å‡§ó‡•ç‡§£‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§â‡§™‡§æ‡§Ø‡§Ø‡•ã‡§ú‡§®‡§æ ‡§ï‡§∞‡§æ.\",\n",
        "]\n",
        "\n",
        "# Tokenize test grievances\n",
        "inputs = tokenizer(test_texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512).to(device)\n"
      ],
      "metadata": {
        "id": "wtebBWYRz5hd"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
        "\n",
        "# Define department mapping (should match training labels)\n",
        "department_map = {\n",
        "    0: \"School Education and Sports\",\n",
        "    1: \"Agriculture Department\",\n",
        "    2: \"Co-operation, Marketing and Textiles Department\",\n",
        "    3: \"Dairy Development Department\",\n",
        "    4: \"Department Of Animal Husbandry\",\n",
        "    5: \"Department Of Minority Development\",\n",
        "    6: \"Department of Industries, Energy, Labor and Mines\",\n",
        "    7: \"Department of Sainik Welfare\",\n",
        "    8: \"Environment and Climate Change Department\",\n",
        "    9: \"Finance Department\",\n",
        "    10: \"Fisheries Department\",\n",
        "    11: \"Food, Civil Supplies and Consumer Protection Department\",\n",
        "    12: \"Forest Department\",\n",
        "    13: \"General Administration Department\",\n",
        "    14: \"Goods and Services Tax Department\",\n",
        "    15: \"Greater Mumbai Police\",\n",
        "    16: \"Higher and Technical Education Department\",\n",
        "    17: \"Home Department\",\n",
        "    18: \"Housing Department\",\n",
        "    19: \"Labour Department\",\n",
        "    20: \"Law and Judiciary Department\"\n",
        "}\n",
        "\n",
        "# Print predictions\n",
        "for text, label in zip(test_texts, predictions):\n",
        "    print(f\"Complaint: {text}\\nPredicted Department: {department_map[label]}\\n{'-'*50}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3vllt2p2vFW",
        "outputId": "7ba771ad-121c-4b74-966c-71c077a120cc"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complaint: ‡§Æ‡§æ‡§ù‡•ç‡§Ø‡§æ ‡§ó‡§æ‡§µ‡§æ‡§§‡•Ä‡§≤ ‡§∞‡§∏‡•ç‡§§‡•ç‡§Ø‡§æ‡§ö‡•Ä ‡§Ö‡§µ‡§∏‡•ç‡§•‡§æ ‡§ñ‡•Ç‡§™‡§ö ‡§µ‡§æ‡§à‡§ü ‡§Ü‡§π‡•á. ‡§™‡§æ‡§µ‡§∏‡§æ‡§≥‡•ç‡§Ø‡§æ‡§§ ‡§ö‡§ø‡§ñ‡§≤‡§æ‡§Æ‡•Å‡§≥‡•á ‡§≤‡•ã‡§ï‡§æ‡§Ç‡§®‡§æ ‡§ö‡§æ‡§≤‡§£‡•á‡§π‡•Ä ‡§ï‡§†‡•Ä‡§£ ‡§π‡•ã‡§§‡•á.\n",
            "Predicted Department: Department Of Minority Development\n",
            "--------------------------------------------------\n",
            "Complaint: ‡§∂‡•á‡§§‡§ï‡§±‡•ç‡§Ø‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§®‡§µ‡•Ä‡§® ‡§Ö‡§®‡•Å‡§¶‡§æ‡§® ‡§ï‡§ß‡•Ä ‡§Æ‡§ø‡§≥‡§£‡§æ‡§∞? ‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä ‡§Æ‡§¶‡§§‡•Ä‡§ö‡§æ ‡§≤‡§æ‡§≠ ‡§Ü‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§Æ‡§ø‡§≥‡§æ‡§µ‡§æ.\n",
            "Predicted Department: Department Of Animal Husbandry\n",
            "--------------------------------------------------\n",
            "Complaint: ‡§µ‡§ø‡§ú‡•á‡§ö‡§æ ‡§∏‡§§‡§§ ‡§™‡•Å‡§∞‡§µ‡§†‡§æ ‡§ñ‡§Ç‡§°‡§ø‡§§ ‡§π‡•ã‡§§‡•ã. ‡§Ü‡§Æ‡•ç‡§π‡§æ‡§≤‡§æ ‡§ñ‡•Ç‡§™ ‡§Ö‡§°‡§ö‡§£ ‡§π‡•ã‡§§‡•á, ‡§ï‡•É‡§™‡§Ø‡§æ ‡§ï‡§æ‡§π‡•Ä‡§§‡§∞‡•Ä ‡§â‡§™‡§æ‡§Ø ‡§ï‡§∞‡§æ.\n",
            "Predicted Department: Department Of Minority Development\n",
            "--------------------------------------------------\n",
            "Complaint: ‡§∏‡§∞‡§ï‡§æ‡§∞‡•Ä ‡§∞‡•Å‡§ó‡•ç‡§£‡§æ‡§≤‡§Ø‡§æ‡§§ ‡§î‡§∑‡§ß‡§æ‡§Ç‡§ö‡§æ ‡§§‡•Å‡§ü‡§µ‡§°‡§æ ‡§Ü‡§π‡•á. ‡§ó‡§∞‡§ú‡•Ç ‡§∞‡•Å‡§ó‡•ç‡§£‡§æ‡§Ç‡§∏‡§æ‡§†‡•Ä ‡§â‡§™‡§æ‡§Ø‡§Ø‡•ã‡§ú‡§®‡§æ ‡§ï‡§∞‡§æ.\n",
            "Predicted Department: Department Of Animal Husbandry\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r fine_tuned_model.zip fine_tuned_indic_bert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhI8ZoE738N3",
        "outputId": "0c0d4596-9702-45fb-c4d4-83793c654bfb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: fine_tuned_indic_bert/ (stored 0%)\n",
            "  adding: fine_tuned_indic_bert/model.safetensors (deflated 7%)\n",
            "  adding: fine_tuned_indic_bert/special_tokens_map.json (deflated 49%)\n",
            "  adding: fine_tuned_indic_bert/spiece.model (deflated 60%)\n",
            "  adding: fine_tuned_indic_bert/tokenizer_config.json (deflated 74%)\n",
            "  adding: fine_tuned_indic_bert/tokenizer.json (deflated 77%)\n",
            "  adding: fine_tuned_indic_bert/config.json (deflated 62%)\n"
          ]
        }
      ]
    }
  ]
}